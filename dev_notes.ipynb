{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b0c2d4",
   "metadata": {},
   "source": [
    "# üìí Dev Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebaf997",
   "metadata": {},
   "source": [
    "### üñ•Ô∏è Frontend Workflow (Streamlit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429cb4dd",
   "metadata": {},
   "source": [
    "**1. Configuration Setup** <br>\n",
    "Created a `ui_config_file.ini` to store constants like:\n",
    "\n",
    "* Page title\n",
    "\n",
    "* LLM options\n",
    "\n",
    "* Use-case types\n",
    "\n",
    "* Groq model choices\n",
    "\n",
    "**2. Config Parser** <br>\n",
    "Implemented `ui_config_file.py` to parse and expose values from the `.ini` file.\n",
    "\n",
    "**3. UI Loader** <br>\n",
    "Used the parsed config in `load_ui.py` to build the sidebar and user controls.\n",
    "\n",
    "**4. Main UI Logic** <br>\n",
    "`main.py` sets up the Streamlit layout and integrates the sidebar and input elements.\n",
    "\n",
    "**5. Entry Point** <br>\n",
    "`app.py` acts as the app‚Äôs entry point, triggering the entire UI flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52e3db",
   "metadata": {},
   "source": [
    "### üß† Implementing the LLM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd471c",
   "metadata": {},
   "source": [
    "**1. LLM Handler** <br>\n",
    "`groq_llm.py` defines a `GroqLLM` class to manage model configuration.\n",
    "\n",
    "**2. Key Retrieval** <br>\n",
    "Takes the Groq API key and selected model from UI controls.\n",
    "\n",
    "**3. LLM Instantiation** <br>\n",
    "Initializes a `ChatGroq` instance using the provided configuration.\n",
    "\n",
    "**4. Validation** <br>\n",
    "Validates API key input and raises error if invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff866b2",
   "metadata": {},
   "source": [
    "### üõ† Building Graph  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4655f0b1",
   "metadata": {},
   "source": [
    "**1. State Definition** <br>\n",
    "Defined a `State` class in `state.py` using `TypedDict`, with:\n",
    "\n",
    "* `message`: list of messages\n",
    "\n",
    "* Annotated with `add_messages` to auto-append messages\n",
    "\n",
    "**2. Graph Initialization** <br>\n",
    "In `graph_builder.py`, initialized a `StateGraph` with the custom `State`.\n",
    "\n",
    "**3. Graph Construction** <br>\n",
    "Inside `basic_chatbot_build_graph()`, added:\n",
    "\n",
    "* A `\"chatbot\"` node \n",
    "\n",
    "* Edges from `START ‚Üí chatbot ‚Üí END`\n",
    "\n",
    "**4. LLM Integration** <br>\n",
    "The `GraphBuilder` class takes in the LLM model instance during initialization, ready for use in node logic.\n",
    "\n",
    "**5. Result** <br>\n",
    "A minimal working chatbot graph with a single node, ready to be expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06720a82",
   "metadata": {},
   "source": [
    "### ü§ñ Basic Chatbot Node Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8247a169",
   "metadata": {},
   "source": [
    "**1. Node Definition**\n",
    "Created `BasicChatbotNode` class to handle the core chatbot logic in `basic_chatbot_node.py`.\n",
    "\n",
    "**2. Message Processing**\n",
    "The `process()` method:\n",
    "\n",
    "* Takes in a `State` containing user messages\n",
    "\n",
    "* Uses the LLM to generate a response\n",
    " \n",
    "* Returns updated messages as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c59a0e",
   "metadata": {},
   "source": [
    "### üß© Integrating Pipeline with Frontend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81da37d",
   "metadata": {},
   "source": [
    "**1. App Entry Point**\n",
    "Created `app.py` to trigger the app by calling `load_langgraph_agentic_ai_app()` from `main.py`.\n",
    "\n",
    "**2. UI & Orchestration Logic**\n",
    "In `main.py`:\n",
    "\n",
    "* Loads the Streamlit UI and user inputs using `LoadStreamlitUI`\n",
    "\n",
    "* Accepts user input via `st.chat_input()`\n",
    "\n",
    "* Initializes LLM using `GroqLLM`\n",
    "\n",
    "* Sets up graph via `GraphBuilder` based on selected use-case\n",
    "\n",
    "* Displays results using `DisplayResultStreamlit`\n",
    "\n",
    "**3. Result Rendering**\n",
    "In `display_result.py`:\n",
    "\n",
    "* Streams events from the graph based on user input\n",
    "\n",
    "* Displays messages using `st.chat_message(\"user\")` and `st.chat_message(\"assistant\")`\n",
    "\n",
    "* Ensures conversation is shown in real-time for a smooth chat experience"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
